
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  	<title>Ye Tian</title>
    <style>body{font-size: 18px}</style>
  </head>

<body>
<font face="Times New Roman">
<div style = "margin-bottom: 30px; margin-left: auto; margin-right: auto; margin-top: 30px; word-wrap: break-word; width: 900px; ">


<table width="100%", height="200px", border="0", cellspacing="0". style="font-size: 18px">
<tbody>
  <tr><td width="80%">
    <p style="margin-bottom:3cm;"><h1>Ye Tian (田晔)</h1></p>
    <br>
    <p style="margin-bottom:0.5cm;">
    Email: yetian1015 (at) gmail (dot) com </p>
    <p>
    [<a href="https://www.linkedin.com/in/ye-tian-7a572373/">Linkedin</a>] [<a href="https://scholar.google.com/citations?user=MjQ2VMIAAAAJ&hl=en">Google Scholar</a>]
    </p>
  </td>
  
  <td width="20%">
    <p><div align="center">
      <img src="YeTian.jpg" alt="portrait" style="float:right;width:143px;height:200px;" >
    </div></p>
  </td>
  
</tr>
</tbody>
</table>

<hr>
<h2>About Me</h2>
<p>
I received my Ph.D. from the School of Industrial Engineering at Purdue University in 2021, under the supervision of <a href="https://engineering.purdue.edu/~gscutari/">Prof. Gesualdo Scutari</a>.
Previously, I got my B.S. from the Department of Mathematics at Nanjing University in 2016.  
My research interest lies in designing efficient and robust decentralized/distributed optimization algorithms and their application to machine learning.
</p>

<hr>
<h2>Selected Publications</h2>
<ul>
  <P><li>
  <strong>Acceleration in Distributed Optimization under Similarity</strong><br>
  Ye Tian, Gesualdo Scutari, Tianyu Cao, and Alexander Gasnikov<br>
  International Conference on Artificial Intelligence and Statistics (AISTATS) 2022.  [<a href="https://arxiv.org/pdf/2110.12347.pdf">PDF</a>] <br>
  <i>This paper presents an accelerated decentralized optimization algorithm whose communication complexity is nearly optimal, in the presence of similarity among local datasets.  </i></p>
  <P><li>
  <strong>ASY-SONATA: Achieving Geometric Convergence for Distributed Asynchronous Optimization</strong><br>
  Ye Tian, Ying Sun, and Gesualdo Scutari, <br>
  Allerton Conference on Communication, Control, and Computing (Allerton) 2018.
  [<a href="https://arxiv.org/abs/1803.10359">PDF</a>] [<a href="https://github.com/YeTian-93/ASY-SONATA">code</a>]<br>
  <i>1) This paper presents a decentralized asynchronous (first-order) nonconvex optimization algorithm achieving geometric convergence rate for minimizing strongly convex objectives.<br>  2) We adopt the partially asynchronous algorithmic model, which is mathematically general and does not enforce any specific computation/communication protocol. </i></p>
  <P><li>
  <strong>On coding capacity of delay-constrained network information flow: An algebraic approach</strong><br>
  Minghua Chen, Ye Tian, and Chih-Chun Wang, <br>
  IEEE International Symposium on Information Theory (ISIT) 2016.
  [<a href="https://engineering.purdue.edu/~chihw/pub_pdf/16C_d_conv.pdf">PDF</a>]<br>
  <i>This paper characterizes the communication capacity of Linear Network Coding in multicast/broadcast scenario with a hard delay constraint.</i></p>
</ul>
<hr>
<div align="center">
<script src="//t1.extreme-dm.com/f.js" async defer></script>
</div>

</body>
</html>

